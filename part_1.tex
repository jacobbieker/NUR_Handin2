\section{Part 1}

The shared code for this part, as well as the random generator for all the parts is here:

\lstinputlisting{one.py}

\section{Part 1.a Normally Distributed pseudo-random numbers}

The file of the functions used for this exercise is:

\lstinputlisting{one_a.py}

My script produces the following plots, see Fig. \ref{fig:xi_xi}, Fig. \ref{fig:thousand}, and Fig. \ref{fig:million}.
These plots suggest the random number generator is sufficiently random and is not biased towards any numbers.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\linewidth]{./plots/Xi_Xi_1.png}
  \caption{The results of the first 1000 numbers of the random generator. }
  \label{fig:xi_xi}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\linewidth]{./plots/Index_Xi_1.png}
  \caption{First 1000 random numbers vs index.}
  \label{fig:thousand}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\linewidth]{./plots/1000000_rand.png}
  \caption{1,000,000 random numbers plotted in 20 bins 0.05 wide.}
  \label{fig:million}
\end{figure}


\section{Part 1.b Box-Muller Method}

The file of the functions used for this exercise is:

\lstinputlisting{one_b.py}

My script produces the following result, see Fig. \ref{fig:boxmuller}. As can be seen, the Box-Muller implementation seems
to create a Gaussian distribution.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\linewidth]{./plots/box_gauss.png}
  \caption{Box-Muller method.}
  \label{fig:boxmuller}
\end{figure}


\section{Part 1.c KS-test}

The file of the functions used for this exercise is:

\lstinputlisting{one_c.py}

The result of this function is given by the Figures \ref{fig:kstest}, and \ref{fig:kstestP}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\linewidth]{./plots/KStest.png}
  \caption{KS Test.}
  \label{fig:kstest}
\end{figure}


\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\linewidth]{./plots/KStest_pvalue.png}
  \caption{KS Test P-values.}
  \label{fig:kstestP}
\end{figure}

This seems to show that the KS tests are fairly similar in their results, and their results seem to
suggest that the Box-Muller implementation is consistent with a Gaussian distribution.


\section{Part 1.d Kuiper Test}

The file of the functions used for this exercise is:

\lstinputlisting{one_d.py}

My script produces the following result, see Fig. \ref{fig:kuiperTest}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\linewidth]{./plots/KuiperTest.png}
  \caption{Kuiper Test implementation.}
  \label{fig:kuiperTest}
\end{figure}

This seems to show that the probabilities derived from my Kuiper Test differs somewhat from the Kuiper test in Astropy, although the cause for that is unknown. At
the same time, the value for V is similar between both the Astropy version and my own.
It also shows that my the Box-Muller implementation seems to still be consistent with a Gaussian Distribution.


\section{Part 1.e 10 Sets of Numbers}

The file of the functions used for this exercise is:

\lstinputlisting{one_e.py}

My script produces the following result, see Fig. \ref{fig:10_sets}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\linewidth]{./plots/RandNumKS.png}
  \caption{Results of KS Test on 10 sets of numbers.}
  \label{fig:10_sets}
\end{figure}

From this, it seems like the majority of the sets are closeish to Gaussian distributed, but sets 5, 6, and 8 all seem like
they are consistent with a probability greater than 0.8, with Gaussian distributions for $10^5$ points based off the probability given by the KS test on them.
Therefore, I conclude that those sets are consistent with a Gaussian Distribution.

